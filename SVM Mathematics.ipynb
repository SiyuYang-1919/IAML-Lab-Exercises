{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Support Vector Machines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. SVMs overview:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.1 What does SVM learn from the training dataset and labeled data?\n",
    "- A linear model, or a line / hyperplane (for multiple variables);\n",
    "- Now, we have the equation that represents the 'line':\n",
    "$$ y = w^{T}x + w_0 $$\n",
    "- We use an algorithm to determine which are the values of W and b giving the 'best' line seperating the data;\n",
    "- SVM is one of the algorithms that help determine the two parameters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.2 Some background knowledge about SVM\n",
    "- SVMs include SVM (for classification) and SVR (for regression);\n",
    "- Four different SVM:\n",
    "  - The original one : the Maximal Margin Classifier,\n",
    "  - The kernelized version using the Kernel Trick,\n",
    "  - The soft-margin version,\n",
    "  - The soft-margin kernelized version (which combine 1, 2 and 3)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Understanding the Math of SVM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.1 The Margin (concept)\n",
    "1. ```The goal of SVM:```\n",
    "The goal of a support vector machine is to find  the optimal separating hyperplane which maximizes the margin of the training data. \n",
    "2. ```Optimal seperating hyperplane:```The fact that you can find a separating hyperplane,  does not mean it is the best one !\n",
    "<img src=https://www.svm-tutorial.com/wp-content/uploads/2014/11/01_svm-dataset1-separated-2.png width=\"300\" height=\"300\" alt=\"SVM\" align=center>\n",
    "\n",
    "So we will try to select an hyperplane as far as possible from data points from each category. The optimal seperating hyperplane should:\n",
    "- correctly classifies the training data;\n",
    "- generalize better with unseen data.\n",
    "3. ```Margin:``` the optimal hyperplane will be the one with the biggest margin."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.2 Margin Calculation\n",
    "<img src=images/Lab2/SVM1.jpg width=\"200\" height=\"200\" alt=\"SVM1\" align=center>\n",
    "<img src=images/Lab2/SVM2.jpg width=\"200\" height=\"200\" alt=\"SVM2\" align=center>\n",
    "\n",
    "- The distance of one training data (x) to the hyperplane is c, which is equal to |b-a|, while the margin is the distance from the closest training point to the hyperplane, $minimize \\quad c$;\n",
    "\n",
    "- Step 1: calculating b\n",
    "  - z (a vector) has the magnitude of b; its direction is the same as $w$, so its direction would be $\\frac{w}{||w||}$;\n",
    "  - That is, $z = b\\frac{w}{||w||}$;\n",
    "  - z on the hyperplane, so we have $ w^Tz + w_0 = 0$;\n",
    "  $$ w^T \\frac{bw}{||w||} + w_0 = 0 $$\n",
    "  $$ b||w|| + w_0 = 0 $$\n",
    "  $$ b = - \\frac{w_0}{||w||} $$\n",
    "  Note: $||w|| = \\sqrt{w^Tw}$\n",
    "- Step 2: calculating a\n",
    "  - $a$ is the magnituede of $x$'s projection on $w$;\n",
    "  - that is, \n",
    "  $$a = \\frac {w^Tx}{||w||}$$\n",
    "- Step 3: calculating c\n",
    "  - $ c = |b-a| = |\\frac{w_0}{||w||} + \\frac {w^Tx}{||w||}| $\n",
    "  - that is, the distance of one training point \n",
    "  $$ c = \\frac{1}{||w||}|w^Tx + w_0| $$\n",
    "- Step 4: the margin\n",
    "  - therefore, the margin is \n",
    "  $$ min_{i} \\frac{1}{||w||}|w^Tx_i + w_0| $$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.3 The SVM optimisation problem\n",
    "- Scaling: $(w, w_0)$ and $(cw, cw_0)$ define the same hyperplane;\n",
    "- This is because: $cw^Tx + cw_0 \\geq 0$ is equal to $w^Tx + w_0 \\geq 0$;\n",
    "- Put a constraint on $(w, w_0)$, \n",
    "$$ min_{i} \\frac{1}{||w||}|w^Tx_i + w_0| = 1 $$\n",
    "- Now the margin will always be $\\frac{1}{||w||}$;\n",
    "- We want a hyperplane that will maximize the margin:\n",
    "$$ max_w \\frac{1}{||w||} $$\n",
    "subject to: \n",
    "$$w^Tx_i + w_0 \\geq 1 $$, for all i with $y_i = 1$; \n",
    "$$w^Tx_i + w_0 \\leq -1 $$, for all i with $y_i = -1$; \n",
    "$$min_{i} \\frac{1}{||w||}|w^Tx_i + w_0| = 1$$\n",
    "- After deleting the third rebundent restriction and simplifying the first two restrictions, we have:\n",
    "$$ max_w \\frac{1}{2||w||} $$\n",
    "subject to:\n",
    "$$ y_i(w^Tx_i + w_0) \\geq 1 $$, for all i\n",
    "- The above optimization is equal to:\n",
    "$$ min_w ||w||^2 $$\n",
    "subject to:\n",
    "$$ y_i(w^Tx_i + w_0) \\geq 1 $$, for all i"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.4 The solution of optimal paramters\n",
    "- ```Compute w:```\n",
    "$$ w = \\sum_i {\\alpha}_i{y_i}{x_i} $$\n",
    "- ```Compute w_0:```\n",
    "  - we can use a constraint to calculate $w_0$:\n",
    "$$ y_i(w^Tx_i + w_0) = 1 $$\n",
    "  - multiply $y_i$ at each side (note ${y_i}^2 = 1$),\n",
    "$$ w^Tx_i + w_0 = y_i $$\n",
    "$$ w_0 = y_i - w^Tx_i $$\n",
    "- ```Hypothesis function:```\n",
    "  - therefore, prediction on new data point $x$ is:\n",
    "$$ f(x) = sign((w^Tx) + w_0) $$\n",
    "$$ = sign(\\sum_i^n {\\alpha}_i{y_i}({x_i^T}x) + w_0)$$\n",
    "- The formulation of the SVM is the hard margin SVM. It can not work when the data is not linearly separable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3. Soft Margin SVM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 3.1 When and how soft margin SVM helps?\n",
    "<img src=images/Lab2/Soft SVM1.jpg width=\"200\" height=\"200\" alt=\"SVM3\" align=center>\n",
    "<img src=images/Lab2/Soft SVM2.jpg width=\"200\" height=\"200\" alt=\"SVM4\" align=center>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}